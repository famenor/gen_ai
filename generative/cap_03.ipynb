{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6582cb35-b8e3-4dd4-a90f-8e2bfe0d679d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ae9bbb0-ef44-4aa8-af73-0dc966e1c195",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['OPENAI_API_KEY'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "87177dc9-4cf9-4fde-9911-76d8216bbc14",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "31b85004-b1db-4933-87da-2765f94b4ea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dall-e-3 model system\n",
      "dall-e-2 model system\n",
      "o1-mini-2024-09-12 model system\n",
      "gpt-4o-mini-realtime-preview-2024-12-17 model system\n",
      "o1-preview-2024-09-12 model system\n",
      "o1-mini model system\n",
      "o1-preview model system\n",
      "gpt-4o-mini-realtime-preview model system\n",
      "gpt-4o-mini-audio-preview-2024-12-17 model system\n",
      "whisper-1 model openai-internal\n",
      "gpt-4-turbo model system\n",
      "gpt-4o-mini-audio-preview model system\n",
      "gpt-4o-audio-preview-2024-10-01 model system\n",
      "gpt-4o-realtime-preview-2024-10-01 model system\n",
      "babbage-002 model system\n",
      "omni-moderation-latest model system\n",
      "omni-moderation-2024-09-26 model system\n",
      "tts-1-hd-1106 model system\n",
      "gpt-4o-audio-preview-2024-12-17 model system\n",
      "gpt-4-0125-preview model system\n",
      "gpt-4o-audio-preview model system\n",
      "chatgpt-4o-latest model system\n",
      "gpt-4o-2024-11-20 model system\n",
      "tts-1-hd model system\n",
      "gpt-4o-2024-08-06 model system\n",
      "gpt-4o model system\n",
      "gpt-4-turbo-2024-04-09 model system\n",
      "tts-1 model openai-internal\n",
      "tts-1-1106 model system\n",
      "davinci-002 model system\n",
      "gpt-3.5-turbo-1106 model system\n",
      "gpt-4o-2024-05-13 model system\n",
      "gpt-3.5-turbo-instruct model system\n",
      "gpt-3.5-turbo-instruct-0914 model system\n",
      "gpt-3.5-turbo-0125 model system\n",
      "gpt-4o-realtime-preview-2024-12-17 model system\n",
      "gpt-3.5-turbo model openai\n",
      "gpt-4o-mini model system\n",
      "gpt-4o-realtime-preview model system\n",
      "gpt-3.5-turbo-16k model openai-internal\n",
      "gpt-4o-mini-2024-07-18 model system\n",
      "text-embedding-3-small model system\n",
      "gpt-4 model openai\n",
      "text-embedding-ada-002 model openai-internal\n",
      "gpt-4-1106-preview model system\n",
      "gpt-4-0613 model openai\n",
      "text-embedding-3-large model system\n",
      "gpt-4-turbo-preview model system\n"
     ]
    }
   ],
   "source": [
    "#LIST MODELS\n",
    "models = client.models.list()\n",
    "for model in models:\n",
    "    print(model.id, model.object, model.owned_by)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f7e3913-6953-4533-9ff5-4ab2a91ace19",
   "metadata": {},
   "source": [
    "# Parametros b√°sicos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29cd68bb-9443-4009-9ab0-3a3b105fd246",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.completions.create(model='gpt-3m.5-turbo-instruct',\n",
    "                                     prompt='Write a few bullets on why love sucks',\n",
    "                                     max_tokens=100,\n",
    "                                     temperature=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1985e678-19d7-4328-b5ac-002964c05b93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Love can be unpredictable and unreliable, leaving us vulnerable to heartbreak or disappointment.\n",
      "- It can cause us to make irrational decisions and put our own needs and well-being aside for the sake of the other person.\n",
      "- The intensity and overwhelming emotions of love can cloud our judgment and lead us to overlook red flags or toxic behaviors in a relationship.\n",
      "- Love can be all-consuming and distracting, making it difficult to focus on other important aspects of our lives such as career, personal growth, and friendships\n"
     ]
    }
   ],
   "source": [
    "print(response.choices[0].text.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dc80eaa2-883c-4a0a-aecb-f0e337ac2cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_startphrase = 'Suggest for a street mexican restaurant, the generated names should be funny and happy.'\n",
    "\n",
    "response = client.completions.create(model='gpt-3.5-turbo-instruct',\n",
    "                                     prompt=prompt_startphrase,\n",
    "                                     max_tokens=100,\n",
    "                                     n=1,\n",
    "                                     temperature=0.2,\n",
    "                                     stop=None,\n",
    "                                     suffix='\\nWacha.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f58613fe-d4d1-46b5-9aa7-f2a7b69bcdce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CompletionChoice(finish_reason='length', index=0, logprobs=None, text='\\n\\nTaco Fiesta\\n\\nSalsa Street\\n\\nBurrito Bonanza\\n\\nQuesadilla Quirks\\n\\nEnchilada Express\\n\\nNachos Nook\\n\\nTostada Time\\n\\nChimichanga Charm\\n\\nFajita Frenzy\\n\\nGuacamole Galore\\n\\nTamales & Tacos\\n\\nCarnitas Corner\\n\\nSizzling Sopes\\n\\nTortilla Tango\\n\\nChurro Cheers\\n\\nMargarita Madness\\n\\nSopes & Smiles\\n\\nTaco Tickle')\n"
     ]
    }
   ],
   "source": [
    "print(response.choices[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "46d6d9c8-cdc4-410a-874e-b1a298b014a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_startphrase = 'Suggest for a street mexican restaurant, the generated names should be funny and happy.'\n",
    "\n",
    "response = client.completions.create(model='gpt-3.5-turbo-instruct',\n",
    "                                     prompt=prompt_startphrase,\n",
    "                                     max_tokens=100,\n",
    "                                     n=1,\n",
    "                                     temperature=1.2,\n",
    "                                     stop=None,\n",
    "                                     suffix='\\nWacha.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7e7ed758-7987-4461-9cd1-5dda01c1ae5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CompletionChoice(finish_reason='stop', index=0, logprobs=None, text=\"\\n\\nSabor Feliz.\\n\\nTaco-tastic.\\n\\nMexi-mania.\\n\\nNachos n' More\\n\\nThe Spicy Sombrero.\\n\\nBurrito Bonanza.\\n\\nSalsa Fiesta.\\n\\nEnchilada Express.\\n\\nGuac n' Roll.\\n\\nHappy Habaneros.\\n\")\n"
     ]
    }
   ],
   "source": [
    "print(response.choices[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ebb98deb-a982-41e9-9765-8266c1b5e2e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_startphrase = 'Suggest for a street mexican restaurant, the generated names should be funny and happy.'\n",
    "\n",
    "response = client.completions.create(model='gpt-3.5-turbo-instruct',\n",
    "                                     prompt=prompt_startphrase,\n",
    "                                     max_tokens=100,\n",
    "                                     n=1,\n",
    "                                     top_p=0.95,\n",
    "                                     stop=None,\n",
    "                                     suffix='\\nWacha.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "41d838ae-939d-4b54-aeb6-13ddd7e1cf4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CompletionChoice(finish_reason='length', index=0, logprobs=None, text='\\n\\nTaco Tease.\\n\\nChili Chomp.\\n\\nBurrito Bounce.\\n\\nEnchilada Express.\\n\\nFiesta Frenzy.\\n\\nSalsa Street.\\n\\nNacho Nation.\\n\\nTortilla Tango.\\n\\nGuacamole Galore.\\n\\nFajita Fiesta.\\n\\nQuesadilla Quirks.\\n\\nTaquito Tambourine.\\n\\nChurro Cheer.\\n\\nTamale Tap.\\n\\nSopes Shuffle.\\n\\nMargarita Madness.\\n\\nTostada Twist.\\n\\nChimichanga Cha-Cha.\\n\\nTamales')\n"
     ]
    }
   ],
   "source": [
    "print(response.choices[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e2d9d10-e03c-4c34-b140-d5dab8b14c94",
   "metadata": {},
   "source": [
    "# Probit para tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0cf7916e-a95a-495a-8867-08e995deb316",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e894f556-1ced-46f4-ab9d-a0943bbb691d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Encoding 'cl100k_base'>\n"
     ]
    }
   ],
   "source": [
    "encoding = tiktoken.encoding_for_model('gpt-3.5-turbo-instruct')\n",
    "print(encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6503d2ca-02ae-4813-8293-eab8fb1e4613",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding_object = tiktoken.get_encoding(\"cl100k_base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "318ed15c-a0df-4493-b88d-66dd96a20813",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "taco [83, 16833]\n",
      "salsa [82, 42926]\n",
      "tortilla [83, 371, 6374]\n",
      "chile [331, 458]\n",
      "pozole [5481, 89, 1286]\n",
      "enchilada [20345, 321, 2649]\n"
     ]
    }
   ],
   "source": [
    "palabras = ['taco', 'salsa', 'tortilla', 'chile', 'pozole', 'enchilada']\n",
    "for palabra in palabras:\n",
    "    tokens = encoding.encode(palabra)\n",
    "    print(palabra, tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "759d6cb5-4e59-4fa9-8189-840bd8ef135c",
   "metadata": {},
   "outputs": [],
   "source": [
    "probabilities = {83:-100, 16833:-100,\n",
    "                 82:-100, 42926:-100}\n",
    "\n",
    "probabilities = {5481:10, 1286:5,\n",
    "                 20345:10, 321:5, 2649:5}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "90b55f8f-b9e5-455f-bfd1-af418b5ff8e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_startphrase = 'Suggest for a street mexican restaurant, the generated names should be funny and happy.'\n",
    "\n",
    "response = client.completions.create(model='gpt-3.5-turbo-instruct',\n",
    "                                     prompt=prompt_startphrase,\n",
    "                                     max_tokens=100,\n",
    "                                     n=1,\n",
    "                                     temperature=0.7,\n",
    "                                     logit_bias=probabilities,\n",
    "                                     stop=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "0ff4d8a6-a330-4353-806c-71f9fe179a3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CompletionChoice(finish_reason='length', index=0, logprobs=None, text=\"\\n\\n1. Nacho Average Taco\\n2. Burrito Bonanza\\n3. Queso Fiesta\\n4. Taco Tango\\n5. Enchilada Extravaganza\\n6. Salsa Sensation\\n7. Chimichanga Cha Cha\\n8. Fajita Frenzy\\n9. Guac & Roll\\n10. Tamale Time\\n11. Taco Tuesday's\\n12. Sizzling Salsa\\n13. Margarita Madness\\n14. Burrito Beach\")\n"
     ]
    }
   ],
   "source": [
    "print(response.choices[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "1de04eb3-a3e1-4b4b-a3b5-80b3b5bba9f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_startphrase = 'Suggest a name for a white horse.'\n",
    "\n",
    "response = client.completions.create(model='gpt-3.5-turbo-instruct',\n",
    "                                     prompt=prompt_startphrase,\n",
    "                                     max_tokens=30,\n",
    "                                     n=1,\n",
    "                                     logprobs=3,\n",
    "                                     temperature=0.7,\n",
    "                                     stop=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "d0a89cd0-a8f9-47d7-a01e-9f395ede9615",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completion(id='cmpl-B4XI2i8bCmKXhR6KfaDDr9UFc6SWM', choices=[CompletionChoice(finish_reason='stop', index=0, logprobs=Logprobs(text_offset=[33, 35, 39], token_logprobs=[-0.1798717, -0.09865091, -0.34169492], tokens=['\\n\\n', 'Snow', 'flake'], top_logprobs=[{'\\n\\n': -0.1798717, '\\n': -1.9449226, ' \\n\\n': -4.3541403}, {'Snow': -0.09865091, '\"': -3.1386232, 'F': -4.277072}, {'flake': -0.34169492, 'dr': -1.9550315, 'ball': -2.9074736}]), text='\\n\\nSnowflake')], created=1740420978, model='gpt-3.5-turbo-instruct:20230824-v2', object='text_completion', system_fingerprint=None, usage=CompletionUsage(completion_tokens=3, prompt_tokens=9, total_tokens=12, completion_tokens_details=None, prompt_tokens_details=None))\n",
      "CompletionChoice(finish_reason='stop', index=0, logprobs=Logprobs(text_offset=[33, 35, 39], token_logprobs=[-0.1798717, -0.09865091, -0.34169492], tokens=['\\n\\n', 'Snow', 'flake'], top_logprobs=[{'\\n\\n': -0.1798717, '\\n': -1.9449226, ' \\n\\n': -4.3541403}, {'Snow': -0.09865091, '\"': -3.1386232, 'F': -4.277072}, {'flake': -0.34169492, 'dr': -1.9550315, 'ball': -2.9074736}]), text='\\n\\nSnowflake')\n"
     ]
    }
   ],
   "source": [
    "print(response)\n",
    "print(response.choices[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad2b1f43-e6cf-4711-966b-e17d4a0bc2fc",
   "metadata": {},
   "source": [
    "# Chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "8ba20fc7-c9ed-43bb-aa17-47a366ce05f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [{'role': 'system', 'content': 'You are and AI assistant that helps people find information'}, \n",
    "            {'role': 'user', 'content': 'Hi there'},\n",
    "            {'role': 'assistant', 'content': 'Hello, How can I assist you today?'},\n",
    "            {'role': 'user', 'content': 'I want to know what is the best month for traveling Cancun'}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "4e87ce42-328d-4fe8-8679-52e2ea0acf18",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(model='gpt-3.5-turbo',\n",
    "                                          messages=messages,\n",
    "                                          temperature=0.7,\n",
    "                                          max_tokens=200,\n",
    "                                          user='amit',\n",
    "                                          top_p=0.95,\n",
    "                                          frequency_penalty=0,\n",
    "                                          presence_penalty=0,\n",
    "                                          stop=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "3c435b19-4af6-47b9-8400-a23e5baea8b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best month for traveling to Cancun typically depends on your preferences and what activities you would like to enjoy. However, generally speaking, the most popular time to visit Cancun is from December to April when the weather is warm and sunny. This period is considered the high season, with peak tourist numbers and higher prices. If you prefer to avoid the crowds and save some money, you may consider visiting during the shoulder seasons of May to June or September to November. Just keep in mind that the weather may be a bit more unpredictable during these times.\n"
     ]
    }
   ],
   "source": [
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "29974f78-b150-4268-987b-8a2889f97e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [{'role': 'system', 'content': 'You are and AI assistant that helps people find information. Answer the questions as if you are a kid'}, \n",
    "            {'role': 'user', 'content': 'Hi there'},\n",
    "            {'role': 'assistant', 'content': 'Hi body'},\n",
    "            {'role': 'user', 'content': 'I want to know what is the best month for traveling Cancun'}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "0e4760af-f358-4cce-8259-b490df70e30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(model='gpt-4o-mini-2024-07-18',\n",
    "                                          messages=messages,\n",
    "                                          temperature=0.7,\n",
    "                                          max_tokens=200,\n",
    "                                          user='amit',\n",
    "                                          top_p=0.95,\n",
    "                                          frequency_penalty=0,\n",
    "                                          presence_penalty=0,\n",
    "                                          stop=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "4411bbd5-0f8c-4c03-9e37-dce37fc752bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oh! I think the best time to go to Cancun is from December to April! The weather is super nice and sunny, not too hot, and it‚Äôs not rainy! Lots of people go then, so it‚Äôs really fun! But if you don‚Äôt like crowds, you could also go in late April or May when it‚Äôs a bit quieter. Just make sure to bring sunscreen!\n"
     ]
    }
   ],
   "source": [
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "3c87743d-d372-4849-93d8-82a53b5d628b",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [{'role': 'system', 'content': 'You are and AI assistant that helps people find information. \\\n",
    "                                           Answer the questions formally, Only answer the questions using the context below. \\\n",
    "                                           Do not make up the answer, if you are not sure of the answer, say \"I do not know\". \\\n",
    "                                           Context: \\\n",
    "                                           - The best months for traveling to Cancun are june and july because they are hot and cheap. \\\n",
    "                                           - The worst months for traveling to Cancun are september and october because there are hurricanes'}, \n",
    "            {'role': 'user', 'content': 'Hi there'},\n",
    "            {'role': 'assistant', 'content': 'Hello, How can I assist you today?'},\n",
    "            {'role': 'user', 'content': 'I want to know what is the best month for traveling Mexico City'}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "02484290-3ccc-43f8-bd17-f056b8ef4576",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(model='gpt-4o-mini-2024-07-18',\n",
    "                                          messages=messages,\n",
    "                                          temperature=0.7,\n",
    "                                          max_tokens=200,\n",
    "                                          user='amit',\n",
    "                                          top_p=0.95,\n",
    "                                          frequency_penalty=0,\n",
    "                                          presence_penalty=0,\n",
    "                                          stop=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "c8f5b358-576e-46ee-b337-c5a988d4f6c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I do not know.\n"
     ]
    }
   ],
   "source": [
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31417dbf-5cd5-43b1-8d5b-d18078c8f524",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
